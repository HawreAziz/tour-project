{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse = void 0;\n\nvar tslib_1 = require(\"tslib\");\n\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\n\nvar types = tslib_1.__importStar(require(\"ast-types\"));\n\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\n\nvar options_1 = require(\"./options\");\n\nvar lines_1 = require(\"./lines\");\n\nvar comments_1 = require(\"./comments\");\n\nvar util = tslib_1.__importStar(require(\"./util\"));\n\nfunction parse(source, options) {\n  options = options_1.normalize(options);\n  var lines = lines_1.fromString(source, options);\n  var sourceWithoutTabs = lines.toString({\n    tabWidth: options.tabWidth,\n    reuseWhitespace: false,\n    useTabs: false\n  });\n  var comments = [];\n  var ast = options.parser.parse(sourceWithoutTabs, {\n    jsx: true,\n    loc: true,\n    locations: true,\n    range: options.range,\n    comment: true,\n    onComment: comments,\n    tolerant: util.getOption(options, \"tolerant\", true),\n    ecmaVersion: 6,\n    sourceType: util.getOption(options, \"sourceType\", \"module\")\n  }); // Use ast.tokens if possible, and otherwise fall back to the Esprima\n  // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n  // automatically, but custom parsers might need additional configuration\n  // to avoid this fallback.\n\n  var tokens = Array.isArray(ast.tokens) ? ast.tokens : require(\"esprima\").tokenize(sourceWithoutTabs, {\n    loc: true\n  }); // We will reattach the tokens array to the file object below.\n\n  delete ast.tokens; // Make sure every token has a token.value string.\n\n  tokens.forEach(function (token) {\n    if (typeof token.value !== \"string\") {\n      token.value = lines.sliceString(token.loc.start, token.loc.end);\n    }\n  });\n\n  if (Array.isArray(ast.comments)) {\n    comments = ast.comments;\n    delete ast.comments;\n  }\n\n  if (ast.loc) {\n    // If the source was empty, some parsers give loc.{start,end}.line\n    // values of 0, instead of the minimum of 1.\n    util.fixFaultyLocations(ast, lines);\n  } else {\n    ast.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos()\n    };\n  }\n\n  ast.loc.lines = lines;\n  ast.loc.indent = 0;\n  var file;\n  var program;\n\n  if (ast.type === \"Program\") {\n    program = ast; // In order to ensure we reprint leading and trailing program\n    // comments, wrap the original Program node with a File node. Only\n    // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n    // node. Most other (Babylon-like) parsers return a File.\n\n    file = b.file(ast, options.sourceFileName || null);\n    file.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos(),\n      lines: lines,\n      indent: 0\n    };\n  } else if (ast.type === \"File\") {\n    file = ast;\n    program = file.program;\n  } // Expose file.tokens unless the caller passed false for options.tokens.\n\n\n  if (options.tokens) {\n    file.tokens = tokens;\n  } // Expand the Program's .loc to include all comments (not just those\n  // attached to the Program node, as its children may have comments as\n  // well), since sometimes program.loc.{start,end} will coincide with the\n  // .loc.{start,end} of the first and last *statements*, mistakenly\n  // excluding comments that fall outside that region.\n\n\n  var trueProgramLoc = util.getTrueLoc({\n    type: program.type,\n    loc: program.loc,\n    body: [],\n    comments: comments\n  }, lines);\n  program.loc.start = trueProgramLoc.start;\n  program.loc.end = trueProgramLoc.end; // Passing file.program here instead of just file means that initial\n  // comments will be attached to program.body[0] instead of program.\n\n  comments_1.attach(comments, program.body.length ? file.program : file, lines); // Return a copy of the original AST so that any changes made may be\n  // compared to the original.\n\n  return new TreeCopier(lines, tokens).copy(file);\n}\n\nexports.parse = parse;\n\nvar TreeCopier = function TreeCopier(lines, tokens) {\n  assert_1.default.ok(this instanceof TreeCopier);\n  this.lines = lines;\n  this.tokens = tokens;\n  this.startTokenIndex = 0;\n  this.endTokenIndex = tokens.length;\n  this.indent = 0;\n  this.seen = new Map();\n};\n\nvar TCp = TreeCopier.prototype;\n\nTCp.copy = function (node) {\n  if (this.seen.has(node)) {\n    return this.seen.get(node);\n  }\n\n  if (isArray.check(node)) {\n    var copy_1 = new Array(node.length);\n    this.seen.set(node, copy_1);\n    node.forEach(function (item, i) {\n      copy_1[i] = this.copy(item);\n    }, this);\n    return copy_1;\n  }\n\n  if (!isObject.check(node)) {\n    return node;\n  }\n\n  util.fixFaultyLocations(node, this.lines);\n  var copy = Object.create(Object.getPrototypeOf(node), {\n    original: {\n      // Provide a link from the copy to the original.\n      value: node,\n      configurable: false,\n      enumerable: false,\n      writable: true\n    }\n  });\n  this.seen.set(node, copy);\n  var loc = node.loc;\n  var oldIndent = this.indent;\n  var newIndent = oldIndent;\n  var oldStartTokenIndex = this.startTokenIndex;\n  var oldEndTokenIndex = this.endTokenIndex;\n\n  if (loc) {\n    // When node is a comment, we set node.loc.indent to\n    // node.loc.start.column so that, when/if we print the comment by\n    // itself, we can strip that much whitespace from the left margin of\n    // the comment. This only really matters for multiline Block comments,\n    // but it doesn't hurt for Line comments.\n    if (node.type === \"Block\" || node.type === \"Line\" || node.type === \"CommentBlock\" || node.type === \"CommentLine\" || this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n      newIndent = this.indent = loc.start.column;\n    } // Every node.loc has a reference to the original source lines as well\n    // as a complete list of source tokens.\n\n\n    loc.lines = this.lines;\n    loc.tokens = this.tokens;\n    loc.indent = newIndent; // Set loc.start.token and loc.end.token such that\n    // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n    // all the tokens that make up this node.\n\n    this.findTokenRange(loc);\n  }\n\n  var keys = Object.keys(node);\n  var keyCount = keys.length;\n\n  for (var i = 0; i < keyCount; ++i) {\n    var key = keys[i];\n\n    if (key === \"loc\") {\n      copy[key] = node[key];\n    } else if (key === \"tokens\" && node.type === \"File\") {\n      // Preserve file.tokens (uncopied) in case client code cares about\n      // it, even though Recast ignores it when reprinting.\n      copy[key] = node[key];\n    } else {\n      copy[key] = this.copy(node[key]);\n    }\n  }\n\n  this.indent = oldIndent;\n  this.startTokenIndex = oldStartTokenIndex;\n  this.endTokenIndex = oldEndTokenIndex;\n  return copy;\n}; // If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\n\n\nTCp.findTokenRange = function (loc) {\n  // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n  // *after* loc.start, we need to rewind this.startTokenIndex first.\n  while (this.startTokenIndex > 0) {\n    var token = loc.tokens[this.startTokenIndex];\n\n    if (util.comparePos(loc.start, token.loc.start) < 0) {\n      --this.startTokenIndex;\n    } else break;\n  } // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n  // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n\n\n  while (this.endTokenIndex < loc.tokens.length) {\n    var token = loc.tokens[this.endTokenIndex];\n\n    if (util.comparePos(token.loc.end, loc.end) < 0) {\n      ++this.endTokenIndex;\n    } else break;\n  } // Increment this.startTokenIndex until we've found the first token\n  // contained by this node.\n\n\n  while (this.startTokenIndex < this.endTokenIndex) {\n    var token = loc.tokens[this.startTokenIndex];\n\n    if (util.comparePos(token.loc.start, loc.start) < 0) {\n      ++this.startTokenIndex;\n    } else break;\n  } // Index into loc.tokens of the first token within this node.\n\n\n  loc.start.token = this.startTokenIndex; // Decrement this.endTokenIndex until we've found the first token after\n  // this node (not contained by the node).\n\n  while (this.endTokenIndex > this.startTokenIndex) {\n    var token = loc.tokens[this.endTokenIndex - 1];\n\n    if (util.comparePos(loc.end, token.loc.end) < 0) {\n      --this.endTokenIndex;\n    } else break;\n  } // Index into loc.tokens of the first token *after* this node.\n  // If loc.start.token === loc.end.token, the node contains no tokens,\n  // and the index is that of the next token following this node.\n\n\n  loc.end.token = this.endTokenIndex;\n};","map":{"version":3,"names":["Object","defineProperty","exports","value","parse","tslib_1","require","assert_1","__importDefault","types","__importStar","b","builders","isObject","builtInTypes","object","isArray","array","options_1","lines_1","comments_1","util","source","options","normalize","lines","fromString","sourceWithoutTabs","toString","tabWidth","reuseWhitespace","useTabs","comments","ast","parser","jsx","loc","locations","range","comment","onComment","tolerant","getOption","ecmaVersion","sourceType","tokens","Array","tokenize","forEach","token","sliceString","start","end","fixFaultyLocations","firstPos","lastPos","indent","file","program","type","sourceFileName","trueProgramLoc","getTrueLoc","body","attach","length","TreeCopier","copy","default","ok","startTokenIndex","endTokenIndex","seen","Map","TCp","prototype","node","has","get","check","copy_1","set","item","i","create","getPrototypeOf","original","configurable","enumerable","writable","oldIndent","newIndent","oldStartTokenIndex","oldEndTokenIndex","isPrecededOnlyByWhitespace","column","findTokenRange","keys","keyCount","key","comparePos"],"sources":["/home/haziz1/node_modules/recast/lib/parser.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.parse = void 0;\nvar tslib_1 = require(\"tslib\");\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\nvar types = tslib_1.__importStar(require(\"ast-types\"));\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\nvar options_1 = require(\"./options\");\nvar lines_1 = require(\"./lines\");\nvar comments_1 = require(\"./comments\");\nvar util = tslib_1.__importStar(require(\"./util\"));\nfunction parse(source, options) {\n    options = options_1.normalize(options);\n    var lines = lines_1.fromString(source, options);\n    var sourceWithoutTabs = lines.toString({\n        tabWidth: options.tabWidth,\n        reuseWhitespace: false,\n        useTabs: false,\n    });\n    var comments = [];\n    var ast = options.parser.parse(sourceWithoutTabs, {\n        jsx: true,\n        loc: true,\n        locations: true,\n        range: options.range,\n        comment: true,\n        onComment: comments,\n        tolerant: util.getOption(options, \"tolerant\", true),\n        ecmaVersion: 6,\n        sourceType: util.getOption(options, \"sourceType\", \"module\"),\n    });\n    // Use ast.tokens if possible, and otherwise fall back to the Esprima\n    // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n    // automatically, but custom parsers might need additional configuration\n    // to avoid this fallback.\n    var tokens = Array.isArray(ast.tokens)\n        ? ast.tokens\n        : require(\"esprima\").tokenize(sourceWithoutTabs, {\n            loc: true,\n        });\n    // We will reattach the tokens array to the file object below.\n    delete ast.tokens;\n    // Make sure every token has a token.value string.\n    tokens.forEach(function (token) {\n        if (typeof token.value !== \"string\") {\n            token.value = lines.sliceString(token.loc.start, token.loc.end);\n        }\n    });\n    if (Array.isArray(ast.comments)) {\n        comments = ast.comments;\n        delete ast.comments;\n    }\n    if (ast.loc) {\n        // If the source was empty, some parsers give loc.{start,end}.line\n        // values of 0, instead of the minimum of 1.\n        util.fixFaultyLocations(ast, lines);\n    }\n    else {\n        ast.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n        };\n    }\n    ast.loc.lines = lines;\n    ast.loc.indent = 0;\n    var file;\n    var program;\n    if (ast.type === \"Program\") {\n        program = ast;\n        // In order to ensure we reprint leading and trailing program\n        // comments, wrap the original Program node with a File node. Only\n        // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n        // node. Most other (Babylon-like) parsers return a File.\n        file = b.file(ast, options.sourceFileName || null);\n        file.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n            lines: lines,\n            indent: 0,\n        };\n    }\n    else if (ast.type === \"File\") {\n        file = ast;\n        program = file.program;\n    }\n    // Expose file.tokens unless the caller passed false for options.tokens.\n    if (options.tokens) {\n        file.tokens = tokens;\n    }\n    // Expand the Program's .loc to include all comments (not just those\n    // attached to the Program node, as its children may have comments as\n    // well), since sometimes program.loc.{start,end} will coincide with the\n    // .loc.{start,end} of the first and last *statements*, mistakenly\n    // excluding comments that fall outside that region.\n    var trueProgramLoc = util.getTrueLoc({\n        type: program.type,\n        loc: program.loc,\n        body: [],\n        comments: comments,\n    }, lines);\n    program.loc.start = trueProgramLoc.start;\n    program.loc.end = trueProgramLoc.end;\n    // Passing file.program here instead of just file means that initial\n    // comments will be attached to program.body[0] instead of program.\n    comments_1.attach(comments, program.body.length ? file.program : file, lines);\n    // Return a copy of the original AST so that any changes made may be\n    // compared to the original.\n    return new TreeCopier(lines, tokens).copy(file);\n}\nexports.parse = parse;\nvar TreeCopier = function TreeCopier(lines, tokens) {\n    assert_1.default.ok(this instanceof TreeCopier);\n    this.lines = lines;\n    this.tokens = tokens;\n    this.startTokenIndex = 0;\n    this.endTokenIndex = tokens.length;\n    this.indent = 0;\n    this.seen = new Map();\n};\nvar TCp = TreeCopier.prototype;\nTCp.copy = function (node) {\n    if (this.seen.has(node)) {\n        return this.seen.get(node);\n    }\n    if (isArray.check(node)) {\n        var copy_1 = new Array(node.length);\n        this.seen.set(node, copy_1);\n        node.forEach(function (item, i) {\n            copy_1[i] = this.copy(item);\n        }, this);\n        return copy_1;\n    }\n    if (!isObject.check(node)) {\n        return node;\n    }\n    util.fixFaultyLocations(node, this.lines);\n    var copy = Object.create(Object.getPrototypeOf(node), {\n        original: {\n            // Provide a link from the copy to the original.\n            value: node,\n            configurable: false,\n            enumerable: false,\n            writable: true,\n        },\n    });\n    this.seen.set(node, copy);\n    var loc = node.loc;\n    var oldIndent = this.indent;\n    var newIndent = oldIndent;\n    var oldStartTokenIndex = this.startTokenIndex;\n    var oldEndTokenIndex = this.endTokenIndex;\n    if (loc) {\n        // When node is a comment, we set node.loc.indent to\n        // node.loc.start.column so that, when/if we print the comment by\n        // itself, we can strip that much whitespace from the left margin of\n        // the comment. This only really matters for multiline Block comments,\n        // but it doesn't hurt for Line comments.\n        if (node.type === \"Block\" ||\n            node.type === \"Line\" ||\n            node.type === \"CommentBlock\" ||\n            node.type === \"CommentLine\" ||\n            this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n            newIndent = this.indent = loc.start.column;\n        }\n        // Every node.loc has a reference to the original source lines as well\n        // as a complete list of source tokens.\n        loc.lines = this.lines;\n        loc.tokens = this.tokens;\n        loc.indent = newIndent;\n        // Set loc.start.token and loc.end.token such that\n        // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n        // all the tokens that make up this node.\n        this.findTokenRange(loc);\n    }\n    var keys = Object.keys(node);\n    var keyCount = keys.length;\n    for (var i = 0; i < keyCount; ++i) {\n        var key = keys[i];\n        if (key === \"loc\") {\n            copy[key] = node[key];\n        }\n        else if (key === \"tokens\" && node.type === \"File\") {\n            // Preserve file.tokens (uncopied) in case client code cares about\n            // it, even though Recast ignores it when reprinting.\n            copy[key] = node[key];\n        }\n        else {\n            copy[key] = this.copy(node[key]);\n        }\n    }\n    this.indent = oldIndent;\n    this.startTokenIndex = oldStartTokenIndex;\n    this.endTokenIndex = oldEndTokenIndex;\n    return copy;\n};\n// If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\nTCp.findTokenRange = function (loc) {\n    // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n    // *after* loc.start, we need to rewind this.startTokenIndex first.\n    while (this.startTokenIndex > 0) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(loc.start, token.loc.start) < 0) {\n            --this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n    // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n    while (this.endTokenIndex < loc.tokens.length) {\n        var token = loc.tokens[this.endTokenIndex];\n        if (util.comparePos(token.loc.end, loc.end) < 0) {\n            ++this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Increment this.startTokenIndex until we've found the first token\n    // contained by this node.\n    while (this.startTokenIndex < this.endTokenIndex) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(token.loc.start, loc.start) < 0) {\n            ++this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token within this node.\n    loc.start.token = this.startTokenIndex;\n    // Decrement this.endTokenIndex until we've found the first token after\n    // this node (not contained by the node).\n    while (this.endTokenIndex > this.startTokenIndex) {\n        var token = loc.tokens[this.endTokenIndex - 1];\n        if (util.comparePos(loc.end, token.loc.end) < 0) {\n            --this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token *after* this node.\n    // If loc.start.token === loc.end.token, the node contains no tokens,\n    // and the index is that of the next token following this node.\n    loc.end.token = this.endTokenIndex;\n};\n"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;EAAEC,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,KAAR,GAAgB,KAAK,CAArB;;AACA,IAAIC,OAAO,GAAGC,OAAO,CAAC,OAAD,CAArB;;AACA,IAAIC,QAAQ,GAAGF,OAAO,CAACG,eAAR,CAAwBF,OAAO,CAAC,QAAD,CAA/B,CAAf;;AACA,IAAIG,KAAK,GAAGJ,OAAO,CAACK,YAAR,CAAqBJ,OAAO,CAAC,WAAD,CAA5B,CAAZ;;AACA,IAAIK,CAAC,GAAGF,KAAK,CAACG,QAAd;AACA,IAAIC,QAAQ,GAAGJ,KAAK,CAACK,YAAN,CAAmBC,MAAlC;AACA,IAAIC,OAAO,GAAGP,KAAK,CAACK,YAAN,CAAmBG,KAAjC;;AACA,IAAIC,SAAS,GAAGZ,OAAO,CAAC,WAAD,CAAvB;;AACA,IAAIa,OAAO,GAAGb,OAAO,CAAC,SAAD,CAArB;;AACA,IAAIc,UAAU,GAAGd,OAAO,CAAC,YAAD,CAAxB;;AACA,IAAIe,IAAI,GAAGhB,OAAO,CAACK,YAAR,CAAqBJ,OAAO,CAAC,QAAD,CAA5B,CAAX;;AACA,SAASF,KAAT,CAAekB,MAAf,EAAuBC,OAAvB,EAAgC;EAC5BA,OAAO,GAAGL,SAAS,CAACM,SAAV,CAAoBD,OAApB,CAAV;EACA,IAAIE,KAAK,GAAGN,OAAO,CAACO,UAAR,CAAmBJ,MAAnB,EAA2BC,OAA3B,CAAZ;EACA,IAAII,iBAAiB,GAAGF,KAAK,CAACG,QAAN,CAAe;IACnCC,QAAQ,EAAEN,OAAO,CAACM,QADiB;IAEnCC,eAAe,EAAE,KAFkB;IAGnCC,OAAO,EAAE;EAH0B,CAAf,CAAxB;EAKA,IAAIC,QAAQ,GAAG,EAAf;EACA,IAAIC,GAAG,GAAGV,OAAO,CAACW,MAAR,CAAe9B,KAAf,CAAqBuB,iBAArB,EAAwC;IAC9CQ,GAAG,EAAE,IADyC;IAE9CC,GAAG,EAAE,IAFyC;IAG9CC,SAAS,EAAE,IAHmC;IAI9CC,KAAK,EAAEf,OAAO,CAACe,KAJ+B;IAK9CC,OAAO,EAAE,IALqC;IAM9CC,SAAS,EAAER,QANmC;IAO9CS,QAAQ,EAAEpB,IAAI,CAACqB,SAAL,CAAenB,OAAf,EAAwB,UAAxB,EAAoC,IAApC,CAPoC;IAQ9CoB,WAAW,EAAE,CARiC;IAS9CC,UAAU,EAAEvB,IAAI,CAACqB,SAAL,CAAenB,OAAf,EAAwB,YAAxB,EAAsC,QAAtC;EATkC,CAAxC,CAAV,CAT4B,CAoB5B;EACA;EACA;EACA;;EACA,IAAIsB,MAAM,GAAGC,KAAK,CAAC9B,OAAN,CAAciB,GAAG,CAACY,MAAlB,IACPZ,GAAG,CAACY,MADG,GAEPvC,OAAO,CAAC,SAAD,CAAP,CAAmByC,QAAnB,CAA4BpB,iBAA5B,EAA+C;IAC7CS,GAAG,EAAE;EADwC,CAA/C,CAFN,CAxB4B,CA6B5B;;EACA,OAAOH,GAAG,CAACY,MAAX,CA9B4B,CA+B5B;;EACAA,MAAM,CAACG,OAAP,CAAe,UAAUC,KAAV,EAAiB;IAC5B,IAAI,OAAOA,KAAK,CAAC9C,KAAb,KAAuB,QAA3B,EAAqC;MACjC8C,KAAK,CAAC9C,KAAN,GAAcsB,KAAK,CAACyB,WAAN,CAAkBD,KAAK,CAACb,GAAN,CAAUe,KAA5B,EAAmCF,KAAK,CAACb,GAAN,CAAUgB,GAA7C,CAAd;IACH;EACJ,CAJD;;EAKA,IAAIN,KAAK,CAAC9B,OAAN,CAAciB,GAAG,CAACD,QAAlB,CAAJ,EAAiC;IAC7BA,QAAQ,GAAGC,GAAG,CAACD,QAAf;IACA,OAAOC,GAAG,CAACD,QAAX;EACH;;EACD,IAAIC,GAAG,CAACG,GAAR,EAAa;IACT;IACA;IACAf,IAAI,CAACgC,kBAAL,CAAwBpB,GAAxB,EAA6BR,KAA7B;EACH,CAJD,MAKK;IACDQ,GAAG,CAACG,GAAJ,GAAU;MACNe,KAAK,EAAE1B,KAAK,CAAC6B,QAAN,EADD;MAENF,GAAG,EAAE3B,KAAK,CAAC8B,OAAN;IAFC,CAAV;EAIH;;EACDtB,GAAG,CAACG,GAAJ,CAAQX,KAAR,GAAgBA,KAAhB;EACAQ,GAAG,CAACG,GAAJ,CAAQoB,MAAR,GAAiB,CAAjB;EACA,IAAIC,IAAJ;EACA,IAAIC,OAAJ;;EACA,IAAIzB,GAAG,CAAC0B,IAAJ,KAAa,SAAjB,EAA4B;IACxBD,OAAO,GAAGzB,GAAV,CADwB,CAExB;IACA;IACA;IACA;;IACAwB,IAAI,GAAG9C,CAAC,CAAC8C,IAAF,CAAOxB,GAAP,EAAYV,OAAO,CAACqC,cAAR,IAA0B,IAAtC,CAAP;IACAH,IAAI,CAACrB,GAAL,GAAW;MACPe,KAAK,EAAE1B,KAAK,CAAC6B,QAAN,EADA;MAEPF,GAAG,EAAE3B,KAAK,CAAC8B,OAAN,EAFE;MAGP9B,KAAK,EAAEA,KAHA;MAIP+B,MAAM,EAAE;IAJD,CAAX;EAMH,CAbD,MAcK,IAAIvB,GAAG,CAAC0B,IAAJ,KAAa,MAAjB,EAAyB;IAC1BF,IAAI,GAAGxB,GAAP;IACAyB,OAAO,GAAGD,IAAI,CAACC,OAAf;EACH,CAzE2B,CA0E5B;;;EACA,IAAInC,OAAO,CAACsB,MAAZ,EAAoB;IAChBY,IAAI,CAACZ,MAAL,GAAcA,MAAd;EACH,CA7E2B,CA8E5B;EACA;EACA;EACA;EACA;;;EACA,IAAIgB,cAAc,GAAGxC,IAAI,CAACyC,UAAL,CAAgB;IACjCH,IAAI,EAAED,OAAO,CAACC,IADmB;IAEjCvB,GAAG,EAAEsB,OAAO,CAACtB,GAFoB;IAGjC2B,IAAI,EAAE,EAH2B;IAIjC/B,QAAQ,EAAEA;EAJuB,CAAhB,EAKlBP,KALkB,CAArB;EAMAiC,OAAO,CAACtB,GAAR,CAAYe,KAAZ,GAAoBU,cAAc,CAACV,KAAnC;EACAO,OAAO,CAACtB,GAAR,CAAYgB,GAAZ,GAAkBS,cAAc,CAACT,GAAjC,CA1F4B,CA2F5B;EACA;;EACAhC,UAAU,CAAC4C,MAAX,CAAkBhC,QAAlB,EAA4B0B,OAAO,CAACK,IAAR,CAAaE,MAAb,GAAsBR,IAAI,CAACC,OAA3B,GAAqCD,IAAjE,EAAuEhC,KAAvE,EA7F4B,CA8F5B;EACA;;EACA,OAAO,IAAIyC,UAAJ,CAAezC,KAAf,EAAsBoB,MAAtB,EAA8BsB,IAA9B,CAAmCV,IAAnC,CAAP;AACH;;AACDvD,OAAO,CAACE,KAAR,GAAgBA,KAAhB;;AACA,IAAI8D,UAAU,GAAG,SAASA,UAAT,CAAoBzC,KAApB,EAA2BoB,MAA3B,EAAmC;EAChDtC,QAAQ,CAAC6D,OAAT,CAAiBC,EAAjB,CAAoB,gBAAgBH,UAApC;EACA,KAAKzC,KAAL,GAAaA,KAAb;EACA,KAAKoB,MAAL,GAAcA,MAAd;EACA,KAAKyB,eAAL,GAAuB,CAAvB;EACA,KAAKC,aAAL,GAAqB1B,MAAM,CAACoB,MAA5B;EACA,KAAKT,MAAL,GAAc,CAAd;EACA,KAAKgB,IAAL,GAAY,IAAIC,GAAJ,EAAZ;AACH,CARD;;AASA,IAAIC,GAAG,GAAGR,UAAU,CAACS,SAArB;;AACAD,GAAG,CAACP,IAAJ,GAAW,UAAUS,IAAV,EAAgB;EACvB,IAAI,KAAKJ,IAAL,CAAUK,GAAV,CAAcD,IAAd,CAAJ,EAAyB;IACrB,OAAO,KAAKJ,IAAL,CAAUM,GAAV,CAAcF,IAAd,CAAP;EACH;;EACD,IAAI5D,OAAO,CAAC+D,KAAR,CAAcH,IAAd,CAAJ,EAAyB;IACrB,IAAII,MAAM,GAAG,IAAIlC,KAAJ,CAAU8B,IAAI,CAACX,MAAf,CAAb;IACA,KAAKO,IAAL,CAAUS,GAAV,CAAcL,IAAd,EAAoBI,MAApB;IACAJ,IAAI,CAAC5B,OAAL,CAAa,UAAUkC,IAAV,EAAgBC,CAAhB,EAAmB;MAC5BH,MAAM,CAACG,CAAD,CAAN,GAAY,KAAKhB,IAAL,CAAUe,IAAV,CAAZ;IACH,CAFD,EAEG,IAFH;IAGA,OAAOF,MAAP;EACH;;EACD,IAAI,CAACnE,QAAQ,CAACkE,KAAT,CAAeH,IAAf,CAAL,EAA2B;IACvB,OAAOA,IAAP;EACH;;EACDvD,IAAI,CAACgC,kBAAL,CAAwBuB,IAAxB,EAA8B,KAAKnD,KAAnC;EACA,IAAI0C,IAAI,GAAGnE,MAAM,CAACoF,MAAP,CAAcpF,MAAM,CAACqF,cAAP,CAAsBT,IAAtB,CAAd,EAA2C;IAClDU,QAAQ,EAAE;MACN;MACAnF,KAAK,EAAEyE,IAFD;MAGNW,YAAY,EAAE,KAHR;MAINC,UAAU,EAAE,KAJN;MAKNC,QAAQ,EAAE;IALJ;EADwC,CAA3C,CAAX;EASA,KAAKjB,IAAL,CAAUS,GAAV,CAAcL,IAAd,EAAoBT,IAApB;EACA,IAAI/B,GAAG,GAAGwC,IAAI,CAACxC,GAAf;EACA,IAAIsD,SAAS,GAAG,KAAKlC,MAArB;EACA,IAAImC,SAAS,GAAGD,SAAhB;EACA,IAAIE,kBAAkB,GAAG,KAAKtB,eAA9B;EACA,IAAIuB,gBAAgB,GAAG,KAAKtB,aAA5B;;EACA,IAAInC,GAAJ,EAAS;IACL;IACA;IACA;IACA;IACA;IACA,IAAIwC,IAAI,CAACjB,IAAL,KAAc,OAAd,IACAiB,IAAI,CAACjB,IAAL,KAAc,MADd,IAEAiB,IAAI,CAACjB,IAAL,KAAc,cAFd,IAGAiB,IAAI,CAACjB,IAAL,KAAc,aAHd,IAIA,KAAKlC,KAAL,CAAWqE,0BAAX,CAAsC1D,GAAG,CAACe,KAA1C,CAJJ,EAIsD;MAClDwC,SAAS,GAAG,KAAKnC,MAAL,GAAcpB,GAAG,CAACe,KAAJ,CAAU4C,MAApC;IACH,CAZI,CAaL;IACA;;;IACA3D,GAAG,CAACX,KAAJ,GAAY,KAAKA,KAAjB;IACAW,GAAG,CAACS,MAAJ,GAAa,KAAKA,MAAlB;IACAT,GAAG,CAACoB,MAAJ,GAAamC,SAAb,CAjBK,CAkBL;IACA;IACA;;IACA,KAAKK,cAAL,CAAoB5D,GAApB;EACH;;EACD,IAAI6D,IAAI,GAAGjG,MAAM,CAACiG,IAAP,CAAYrB,IAAZ,CAAX;EACA,IAAIsB,QAAQ,GAAGD,IAAI,CAAChC,MAApB;;EACA,KAAK,IAAIkB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGe,QAApB,EAA8B,EAAEf,CAAhC,EAAmC;IAC/B,IAAIgB,GAAG,GAAGF,IAAI,CAACd,CAAD,CAAd;;IACA,IAAIgB,GAAG,KAAK,KAAZ,EAAmB;MACfhC,IAAI,CAACgC,GAAD,CAAJ,GAAYvB,IAAI,CAACuB,GAAD,CAAhB;IACH,CAFD,MAGK,IAAIA,GAAG,KAAK,QAAR,IAAoBvB,IAAI,CAACjB,IAAL,KAAc,MAAtC,EAA8C;MAC/C;MACA;MACAQ,IAAI,CAACgC,GAAD,CAAJ,GAAYvB,IAAI,CAACuB,GAAD,CAAhB;IACH,CAJI,MAKA;MACDhC,IAAI,CAACgC,GAAD,CAAJ,GAAY,KAAKhC,IAAL,CAAUS,IAAI,CAACuB,GAAD,CAAd,CAAZ;IACH;EACJ;;EACD,KAAK3C,MAAL,GAAckC,SAAd;EACA,KAAKpB,eAAL,GAAuBsB,kBAAvB;EACA,KAAKrB,aAAL,GAAqBsB,gBAArB;EACA,OAAO1B,IAAP;AACH,CA1ED,C,CA2EA;AACA;AACA;AACA;AACA;;;AACAO,GAAG,CAACsB,cAAJ,GAAqB,UAAU5D,GAAV,EAAe;EAChC;EACA;EACA,OAAO,KAAKkC,eAAL,GAAuB,CAA9B,EAAiC;IAC7B,IAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAKyB,eAAhB,CAAZ;;IACA,IAAIjD,IAAI,CAAC+E,UAAL,CAAgBhE,GAAG,CAACe,KAApB,EAA2BF,KAAK,CAACb,GAAN,CAAUe,KAArC,IAA8C,CAAlD,EAAqD;MACjD,EAAE,KAAKmB,eAAP;IACH,CAFD,MAII;EACP,CAV+B,CAWhC;EACA;;;EACA,OAAO,KAAKC,aAAL,GAAqBnC,GAAG,CAACS,MAAJ,CAAWoB,MAAvC,EAA+C;IAC3C,IAAIhB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAK0B,aAAhB,CAAZ;;IACA,IAAIlD,IAAI,CAAC+E,UAAL,CAAgBnD,KAAK,CAACb,GAAN,CAAUgB,GAA1B,EAA+BhB,GAAG,CAACgB,GAAnC,IAA0C,CAA9C,EAAiD;MAC7C,EAAE,KAAKmB,aAAP;IACH,CAFD,MAII;EACP,CApB+B,CAqBhC;EACA;;;EACA,OAAO,KAAKD,eAAL,GAAuB,KAAKC,aAAnC,EAAkD;IAC9C,IAAItB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAKyB,eAAhB,CAAZ;;IACA,IAAIjD,IAAI,CAAC+E,UAAL,CAAgBnD,KAAK,CAACb,GAAN,CAAUe,KAA1B,EAAiCf,GAAG,CAACe,KAArC,IAA8C,CAAlD,EAAqD;MACjD,EAAE,KAAKmB,eAAP;IACH,CAFD,MAII;EACP,CA9B+B,CA+BhC;;;EACAlC,GAAG,CAACe,KAAJ,CAAUF,KAAV,GAAkB,KAAKqB,eAAvB,CAhCgC,CAiChC;EACA;;EACA,OAAO,KAAKC,aAAL,GAAqB,KAAKD,eAAjC,EAAkD;IAC9C,IAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAJ,CAAW,KAAK0B,aAAL,GAAqB,CAAhC,CAAZ;;IACA,IAAIlD,IAAI,CAAC+E,UAAL,CAAgBhE,GAAG,CAACgB,GAApB,EAAyBH,KAAK,CAACb,GAAN,CAAUgB,GAAnC,IAA0C,CAA9C,EAAiD;MAC7C,EAAE,KAAKmB,aAAP;IACH,CAFD,MAII;EACP,CA1C+B,CA2ChC;EACA;EACA;;;EACAnC,GAAG,CAACgB,GAAJ,CAAQH,KAAR,GAAgB,KAAKsB,aAArB;AACH,CA/CD"},"metadata":{},"sourceType":"script"}